{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFjgOHptiVDm"
      },
      "source": [
        "# Initialization of CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APmNmdGnjM9k"
      },
      "source": [
        "Do upload the model folder from github before running this cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7P6c6E7zikDe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Model...\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Could not locate class 'Sequential'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'class_name': 'Sequential', 'config': {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 28, 28, 1], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'conv2d_2_input'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'batch_input_shape': [None, 28, 28, 1], 'dtype': 'float32', 'filters': 30, 'kernel_size': [5, 5], 'strides': [1, 1], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 15, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 15, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}, 'keras_version': '2.8.0', 'backend': 'tensorflow'}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 251\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m operation\n\u001b[1;32m--> 251\u001b[0m CNN \u001b[38;5;241m=\u001b[39m \u001b[43mConvolutionalNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[1], line 140\u001b[0m, in \u001b[0;36mConvolutionalNeuralNetwork.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/model_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/model.json\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_model()\n",
            "Cell \u001b[1;32mIn[1], line 179\u001b[0m, in \u001b[0;36mConvolutionalNeuralNetwork.load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m loaded_model_json \u001b[38;5;241m=\u001b[39m model_json\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    178\u001b[0m model_json\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 179\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_model_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading weights...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    182\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/model_weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\model.py:579\u001b[0m, in \u001b[0;36mmodel_from_json\u001b[1;34m(json_string, custom_objects)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n\u001b[0;32m    578\u001b[0m model_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_string)\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:694\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 694\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:812\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 812\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m )\n",
            "\u001b[1;31mTypeError\u001b[0m: Could not locate class 'Sequential'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'class_name': 'Sequential', 'config': {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 28, 28, 1], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'conv2d_2_input'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'batch_input_shape': [None, 28, 28, 1], 'dtype': 'float32', 'filters': 30, 'kernel_size': [5, 5], 'strides': [1, 1], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 15, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 15, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}, 'keras_version': '2.8.0', 'backend': 'tensorflow'}"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.models import Sequential, model_from_json\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from os.path import isfile, join\n",
        "from keras import backend as K\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "\n",
        "index_by_directory = {\n",
        "    '0': 0,\n",
        "    '1': 1,\n",
        "    '2': 2,\n",
        "    '3': 3,\n",
        "    '4': 4,\n",
        "    '5': 5,\n",
        "    '6': 6,\n",
        "    '7': 7,\n",
        "    '8': 8,\n",
        "    '9': 9,\n",
        "    '+': 10,\n",
        "    '-': 11,\n",
        "    'x': 12,\n",
        "    'a':13,\n",
        "    'b':14\n",
        "}\n",
        "   \n",
        "\n",
        "def get_index_by_directory(directory):\n",
        "    return index_by_directory[directory]\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    train_data = []\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename), cv2.IMREAD_GRAYSCALE) # Convert to Image to Grayscale\n",
        "        img = ~img # Invert the bits of image 255 -> 0\n",
        "        if img is not None:\n",
        "            _, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) # Set bits > 127 to 1 and <= 127 to 0\n",
        "            ctrs, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "            cnt = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0]) # Sort by x\n",
        "            maxi = 0\n",
        "            for c in cnt:\n",
        "                x, y, w, h = cv2.boundingRect(c)\n",
        "                maxi = max(w*h, maxi)\n",
        "                if maxi == w*h:\n",
        "                    x_max = x\n",
        "                    y_max = y\n",
        "                    w_max = w\n",
        "                    h_max = h\n",
        "            im_crop = thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10] # Crop the image as most as possible\n",
        "            im_resize = cv2.resize(im_crop, (28, 28)) # Resize to (28, 28)\n",
        "            im_resize = np.reshape(im_resize, (784, 1)) # Flat the matrix\n",
        "            train_data.append(im_resize)\n",
        "    return train_data\n",
        "\n",
        "def load_all_imgs():\n",
        "    dataset_dir = \"./datasets/\"\n",
        "    directory_list = listdir(dataset_dir)\n",
        "    first = True\n",
        "    data = []\n",
        "\n",
        "    print('Exporting images...')\n",
        "    for directory in directory_list:\n",
        "        print(directory)\n",
        "        if first:\n",
        "            first = False\n",
        "            data = load_images_from_folder(dataset_dir + directory)\n",
        "            for i in range(0, len(data)):\n",
        "                data[i] = np.append(data[i], [str(get_index_by_directory(directory))])\n",
        "            continue\n",
        "\n",
        "        aux_data = load_images_from_folder(dataset_dir + directory)\n",
        "        for i in range(0, len(aux_data)):\n",
        "            aux_data[i] = np.append(aux_data[i], [str(get_index_by_directory(directory))])\n",
        "        data = np.concatenate((data, aux_data))\n",
        "\n",
        "    df=pd.DataFrame(data,index=None)\n",
        "    df.to_csv('model/train_data.csv',index=False)\n",
        "\n",
        "def extract_imgs(img):\n",
        "    img = ~img # Invert the bits of image 255 -> 0\n",
        "    _, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) # Set bits > 127 to 1 and <= 127 to 0\n",
        "    ctrs, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0]) # Sort by x\n",
        "\n",
        "    img_data = []\n",
        "    rects = []\n",
        "    for c in cnt :\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        rect = [x, y, w, h]\n",
        "        rects.append(rect)\n",
        "\n",
        "    bool_rect = []\n",
        "    # Check when two rectangles collide\n",
        "    for r in rects:\n",
        "        l = []\n",
        "        for rec in rects:\n",
        "            flag = 0\n",
        "            if rec != r:\n",
        "                if r[0] < (rec[0] + rec[2] + 10) and rec[0] < (r[0] + r[2] + 10) and r[1] < (rec[1] + rec[3] + 10) and rec[1] < (r[1] + r[3] + 10):\n",
        "                    flag = 1\n",
        "                l.append(flag)\n",
        "            else:\n",
        "                l.append(0)\n",
        "        bool_rect.append(l)\n",
        "\n",
        "    dump_rect = []\n",
        "    # Discard the small collide rectangle\n",
        "    for i in range(0, len(cnt)):\n",
        "        for j in range(0, len(cnt)):\n",
        "            if bool_rect[i][j] == 1:\n",
        "                area1 = rects[i][2] * rects[i][3]\n",
        "                area2 = rects[j][2] * rects[j][3]\n",
        "                if(area1 == min(area1,area2)):\n",
        "                    dump_rect.append(rects[i])\n",
        "\n",
        "    # Get the final rectangles\n",
        "    final_rect = [i for i in rects if i not in dump_rect]\n",
        "    for r in final_rect:\n",
        "        x = r[0]\n",
        "        y = r[1]\n",
        "        w = r[2]\n",
        "        h = r[3]\n",
        "\n",
        "        im_crop = thresh[y:y+h+10, x:x+w+10] # Crop the image as most as possible\n",
        "        im_resize = cv2.resize(im_crop, (28, 28)) # Resize to (28, 28)\n",
        "        im_resize = np.reshape(im_resize, (1, 28, 28)) # Flat the matrix\n",
        "        img_data.append(im_resize)\n",
        "\n",
        "    return img_data\n",
        "\n",
        "class ConvolutionalNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        if os.path.exists('model/model_weights.h5') and os.path.exists('model/model.json'):\n",
        "            self.load_model()\n",
        "        else:\n",
        "            self.create_model()\n",
        "            self.train_model()\n",
        "            self.export_model()\n",
        "\n",
        "    def create_model(self):\n",
        "        first_conv_num_filters = 30\n",
        "        first_conv_filter_size = 5\n",
        "        second_conv_num_filters = 15\n",
        "        second_conv_filter_size = 3\n",
        "        pool_size = 2\n",
        "\n",
        "        # Create model\n",
        "        print(\"Creating Model...\")\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Conv2D(first_conv_num_filters, first_conv_filter_size, input_shape=(28, 28, 1), activation='relu'))\n",
        "        self.model.add(MaxPooling2D(pool_size=pool_size))\n",
        "        self.model.add(Conv2D(second_conv_num_filters, second_conv_filter_size, activation='relu'))\n",
        "        self.model.add(MaxPooling2D(pool_size=pool_size))\n",
        "        self.model.add(Dropout(0.2))\n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dense(128, activation='relu'))\n",
        "        self.model.add(Dense(50, activation='relu'))\n",
        "        self.model.add(Dense(15, activation='softmax'))\n",
        "\n",
        "        # Compile the model\n",
        "        print(\"Compiling Model...\")\n",
        "        self.model.compile(\n",
        "          optimizer='adam',\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'],\n",
        "        )\n",
        "\n",
        "    def load_model(self):\n",
        "        print('Loading Model...')\n",
        "        model_json = open('model/model.json', 'r')\n",
        "        loaded_model_json = model_json.read()\n",
        "        model_json.close()\n",
        "        loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "        print('Loading weights...')\n",
        "        loaded_model.load_weights(\"model/model_weights.h5\")\n",
        "\n",
        "        self.model = loaded_model\n",
        "\n",
        "    def train_model(self):\n",
        "        if not os.path.exists('model/train_data.csv'):\n",
        "            load_all_imgs()\n",
        "\n",
        "        csv_train_data = pd.read_csv('model/train_data.csv', index_col=False)\n",
        "\n",
        "        # The last column contain the results\n",
        "        y_train = csv_train_data[['784']]\n",
        "        csv_train_data.drop(csv_train_data.columns[[784]], axis=1, inplace=True)\n",
        "        csv_train_data.head()\n",
        "\n",
        "        y_train = np.array(y_train)\n",
        "\n",
        "        x_train = []\n",
        "        for i in range(len(csv_train_data)):\n",
        "            x_train.append(np.array(csv_train_data[i:i+1]).reshape(1, 28, 28))\n",
        "        x_train = np.array(x_train)\n",
        "        x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "\n",
        "        # Train the model.\n",
        "        print('Training model...')\n",
        "        self.model.fit(\n",
        "          x_train,\n",
        "          to_categorical(y_train, num_classes=15),\n",
        "          epochs=10,\n",
        "          batch_size=200,\n",
        "          shuffle=True,\n",
        "          verbose=1\n",
        "        )\n",
        "\n",
        "    def export_model(self):\n",
        "        model_json = self.model.to_json()\n",
        "        with open('model/model.json', 'w') as json_file:\n",
        "            json_file.write(model_json)\n",
        "        self.model.save_weights('model/model_weights.h5')\n",
        "\n",
        "    def predict(self, operationBytes):\n",
        "        Image.open(operationBytes).save('_aux_.png')\n",
        "        img = cv2.imread('_aux_.png',0)\n",
        "        os.remove('_aux_.png')\n",
        "        if img is not None:\n",
        "            img_data = extract_imgs(img)\n",
        "\n",
        "            operation = ''\n",
        "            for i in range(len(img_data)):\n",
        "                img_data[i] = np.array(img_data[i])\n",
        "                img_data[i] = img_data[i].reshape(-1, 28, 28, 1)\n",
        "\n",
        "                pred = self.model.predict(img_data[i])\n",
        "                result=np.argmax(pred,axis=1)\n",
        "                print(result[0])\n",
        "                if result[0] == 10:\n",
        "                    operation += '+'\n",
        "                elif result[0] == 11:\n",
        "                    operation += '-'\n",
        "                elif result[0] == 12:\n",
        "                    operation += 'x'\n",
        "                elif result[0] == 13:\n",
        "                    operation += 'a'\n",
        "                elif result[0] == 14:\n",
        "                    operation += 'b'\n",
        "                else:\n",
        "                    operation += str(result[0])\n",
        "            print(f\"Operation is {operation}\")\n",
        "            return operation\n",
        "CNN = ConvolutionalNeuralNetwork()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQWqlZWo4yFc"
      },
      "source": [
        "## Simple Polynomial Solving Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQUpKJ2C48M5"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary Modules\n",
        "from google.colab.patches import cv2_imshow\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "im = cv2.imread(\"eq.jpeg\",0) # Read the User Image\n",
        "im = cv2.resize(im,(600,200)) # Resize the User Image as per Model Requirement\n",
        "\n",
        "# Thresholding the User Image \n",
        "#===============================\n",
        "ret, thresh = cv2.threshold(im, 127, 255, 0)\n",
        "kernel = np.zeros((3,3),np.uint8)\n",
        "thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
        "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "thresh = thresh[10:,10:]\n",
        "cv2_imshow(thresh)\n",
        "#===============================\n",
        "\n",
        "\n",
        "# Conversion of the threshold image into base64 DataURL\n",
        "# This is done as our model requires base64 string to detect Equation/Polynomial\n",
        "#=================================================\n",
        "retval, buffer_img= cv2.imencode('.png', thresh)\n",
        "data = base64.b64encode(buffer_img)\n",
        "data = str(data)\n",
        "data = str(data)[2:len(data)-1]\n",
        "operation = BytesIO(base64.urlsafe_b64decode(data))\n",
        "#=================================================\n",
        "#Initializing the CNN model\n",
        "CNN = ConvolutionalNeuralNetwork()\n",
        "operation = CNN.predict(operation) # Feeding the base64 string to the the CNN Model\n",
        "print(eval(operation)) #print the result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfSO6jqS6u7V"
      },
      "source": [
        "## Linear Equation in One Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1TPZYfr6yzK"
      },
      "outputs": [],
      "source": [
        "# Function to solve Linear Equation in One Variable\n",
        "def solveEquation(equation,variable) :\n",
        "\n",
        "\tn = len(equation)\n",
        "\tsign = 1\n",
        "\tcoeff = 0\n",
        "\ttotal = 0\n",
        "\ti = 0\n",
        "\n",
        "\tfor j in range(0, n) :\n",
        "\t\n",
        "\t\tif (equation[j] == '+' or\n",
        "\t\t\tequation[j] == '-') :\n",
        "\t\t\n",
        "\t\t\tif (j > i) :\n",
        "\t\t\t\ttotal = (total + sign *\n",
        "\t\t\t\t\t\tfloat(equation[i: j]))\n",
        "\t\t\ti = j\n",
        "\n",
        "\t\telif (equation[j] == variable) :\n",
        "\t\t\n",
        "\t\t\tif ((i == j) or\n",
        "\t\t\t\tequation[j - 1] == '+') :\n",
        "\t\t\t\tcoeff += sign\n",
        "\t\t\telif (equation[j - 1] == '-') :\n",
        "\t\t\t\tcoeff = coeff - sign\n",
        "\t\t\telse :\n",
        "\t\t\t\tcoeff = (coeff + sign *\n",
        "\t\t\t\t\t\tfloat(equation[i: j]))\n",
        "\t\t\ti = j + 1\n",
        "\t\t\n",
        "\n",
        "\t\telif (equation[j] == '=') :\n",
        "\t\t\n",
        "\t\t\tif (j > i) :\n",
        "\t\t\t\ttotal = (total + sign *\n",
        "\t\t\t\t\t\tfloat(equation[i: j]))\n",
        "\t\t\tsign = -1\n",
        "\t\t\ti = j + 1\n",
        "\t\t\n",
        "\n",
        "\tif (i < n) :\n",
        "\t\ttotal = (total + sign *\n",
        "\t\t\t\tfloat(equation[i: len(equation)]))\n",
        "\n",
        "\n",
        "\tif (coeff == 0 and\n",
        "\t\ttotal == 0) :\n",
        "\t\treturn \"Infinite solutions\"\n",
        "\n",
        "\n",
        "\tif (coeff == 0 and total) :\n",
        "\t\treturn \"No solution\"\n",
        "\n",
        "\tans = -total / coeff\n",
        "\treturn float(ans)\n",
        "\n",
        "\n",
        "#Importing the necessary Modules\n",
        "from google.colab.patches import cv2_imshow\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "im = cv2.imread(\"eq.jpeg\",0) # Read the User Image\n",
        "im = cv2.resize(im,(600,200)) # Resize the User Image as per Model Requirement\n",
        "\n",
        "# Thresholding the User Image \n",
        "#===============================\n",
        "ret, thresh = cv2.threshold(im, 127, 255, 0)\n",
        "kernel = np.zeros((3,3),np.uint8)\n",
        "thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
        "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "thresh = thresh[10:,10:]\n",
        "cv2_imshow(thresh)\n",
        "#===============================\n",
        "\n",
        "\n",
        "# Conversion of the threshold image into base64 DataURL\n",
        "# This is done as our model requires base64 string to detect Equation/Polynomial\n",
        "#=================================================\n",
        "retval, buffer_img= cv2.imencode('.png', thresh)\n",
        "data = base64.b64encode(buffer_img)\n",
        "data = str(data)\n",
        "data = str(data)[2:len(data)-1]\n",
        "#=================================================\n",
        "#Initializing the CNN model\n",
        "operation = BytesIO(base64.urlsafe_b64decode(data))\n",
        "CNN = ConvolutionalNeuralNetwork()\n",
        "operation = CNN.predict(operation) # Feeding the base64 string to the the CNN Model\n",
        "if 'a' in operation:\n",
        "  print (\"a = {}\" .\n",
        "        format(solveEquation(operation,'a'))) # Feeding the String output to the solveEquation Function to evaluate the value of variable a\n",
        "if 'b' in operation:\n",
        "  print (\"b = {}\" .\n",
        "        format(solveEquation(operation,'b'))) # Feeding the String output to the solveEquation Function to evaluate the value of variable b\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8NAcGTX7qH9"
      },
      "source": [
        "## Linear Equation in Two Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIKotEvr7tMP"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary Modules\n",
        "from sympy.parsing.sympy_parser import parse_expr\n",
        "from sympy import symbols, Eq, solve\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "ls = []\n",
        "filenames = [\"eq1.jpeg\",\"eq2.jpeg\"] #filenames for the linear equations\n",
        "#Run for loops for two times to get the two eqyations from the images specifed as filenames\n",
        "for i in range(0,2):\n",
        "  im = cv2.imread(filenames[i],0)# Read the User Image\n",
        "  im = cv2.resize(im,(600,200))# Resize the User Image as per Model Requirement\n",
        "\n",
        "  # Thresholding the User Image \n",
        "  #===============================\n",
        "  ret, thresh = cv2.threshold(im, 127, 255, 0)\n",
        "  kernel = np.zeros((3,3),np.uint8)\n",
        "  thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
        "  thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "  thresh = thresh[10:,10:]\n",
        "  cv2_imshow(thresh)\n",
        "  #===============================\n",
        "\n",
        "  # Conversion of the threshold image into base64 DataURL\n",
        "  # This is done as our model requires base64 string to detect Equation/Polynomial\n",
        "  #=================================================\n",
        "  retval, buffer_img= cv2.imencode('.png', thresh)\n",
        "  data = base64.b64encode(buffer_img)\n",
        "  data = str(data)\n",
        "  data = str(data)[2:len(data)-1]\n",
        "  #=================================================\n",
        "  #Initializing the CNN model\n",
        "  operation = BytesIO(base64.urlsafe_b64decode(data))\n",
        "  CNN = ConvolutionalNeuralNetwork()\n",
        "  operation = CNN.predict(operation)\n",
        "  ls.append(operation)\n",
        "  #=================================================\n",
        "\n",
        "#putting both equation in variables \n",
        "eq1 = ls[0]\n",
        "eq2 = ls[1]\n",
        "eq1 = comp(eq1)\n",
        "eq2 = comp(eq2)\n",
        "\n",
        "#Initializing the solving process using the sympy module \n",
        "\n",
        "x, y = symbols('a,b')\n",
        "eq1 = parse_expr(eq1)\n",
        "eq1 = Eq((eq1),0)\n",
        "eq2 = parse_expr(eq2)\n",
        "eq2 = Eq((eq2),0)\n",
        "\n",
        "print(eq1)\n",
        "\n",
        "print(eq2)\n",
        "\n",
        "\n",
        "# solving the equation\n",
        "print(\"Values of 2 unknown variable are as follows:\")\n",
        "  \n",
        "print(solve((eq1, eq2), (x, y)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7THfbLN-8Jos"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Hanwritten Equation Solver.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
